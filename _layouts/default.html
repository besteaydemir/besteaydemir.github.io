<!DOCTYPE HTML>
<html lang="en">

<head>
  <title>Beste Aydemir</title>
  <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
  <meta name="author" content="Beste Aydemir" />
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="style.css" />
  <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;margin-right:auto;margin-left:auto;">
    <tr>
      <td>
        <table style="width:100%;border:0px;border-spacing:0px;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <h1>Beste Aydemir</h1>
              <p>I am an MSc student in Data Science at Ludwig-Maximilian University of Munich.</p>
              <p>  My research interests are vision language models and their applications to embodied agents and autonomous driving. </p>
              <p style="text-align:center">
                <a target="_blank" href="https://mailhide.io/e/1AzQKiqM">Email</a> &nbsp;/&nbsp;
                <a href="https://github.com/besteaydemir">GitHub</a> &nbsp;/&nbsp;
                <a href="https://www.linkedin.com/in/besteaydemir/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="photos/me.jpg">
            </td>
          </tr>
        </table>

        <!-- Projects Section -->
        <h2>Education</h2>
        <table style="width:100%;border-spacing:0px;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="photos/lmu.png" alt="LMU Munich Logo" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <strong>Ludwig Maximilian University of Munich</strong> <br/>
              <em>Master of Science in Data Science, GPA: 1.3 (1 is the best)</em> <br/>
              <ul>
                <li>Relevant Courses: Statistical Reasoning and Inference, Predictive Modeling, Advanced Deep Learning for Robotics</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="photos/bilkent.png" alt="Bilkent University Logo" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <strong>Bilkent University</strong> <br/>
              <em>Bachelor of Science in Electrical and Electronics Engineering (Comprehensive Scholarship); GPA: 3.68/4</em> <br/>
              <ul>
                <li>Relevant Courses: Probability and Statistics, Fundamental Structures of Computer Science, Neural Networks, Algorithms and Programming I-II, Stochastic Models</li>
                <li>Signals and Systems, Linear Algebra and Differential Equations, Nonlinear Systems Theory</li>
              </ul>
            </td>
          </tr>
        </table>
        <!-- Projects Section -->
        <h2>Projects</h2>
        <table style="width:100%;border-spacing:0px;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="photos/avila.png" alt="AViLA Project Image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <strong>AViLA: Asynchronous Vision-Language Agent</strong>
              <br/>
              <a href="https://arxiv.org/abs/2506.18472" style="color:darkblue;">arXiv Paper</a>
              <ul>
                <li>Addressing the problem that in streaming multimodal data, where evidence and queries may appear at different times.</li>
                <li>Introducing a three-module architecture: memory retention, evidence retrieval, and evidence-grounded trigger for answering at the right time.</li>
                <li>Including **AnytimeVQA-1K**, a new benchmark of 1,000 Q&A pairs over 189 long videos to test temporal awareness.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="photos/tum_oxford.png" alt="TUM Oxford Project Image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <strong>Navigation and Manipulation with Vision-Language Models</strong> 
              <br/>
              <em>Collaboration between Technical University of Munich (TUM) and Oxford University</em>
              <br/>
              <a href="https://github.com/besteaydemir/besteaydemir.github.io/blob/master/pdfs/DI_Lab.pdf" style="color:darkblue;">Report</a>
              <ul>
                <li>Class-agnostic 3D instance masks generated using Mask3D + OpenMask3D pipelines, which use CLIP features and 2D SAM masks on SceneFun3D dataset </li>
                <li>Building hierarchical open-vocabulary scene graph with CLIP embeddings, and using Qwen3-14B to extract contextual objects, spatial relations, and functional components</li>
                <li>Using PartField (trained on Objaverse) to decompose point cloud into functional parts (e.g., handles, knobs, cushions).</li>
                <li>Qwen2.5-VL-3B selects the correct functional part from segmented components using labeled 2D renderings</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="photos/streaming_drive.png" alt="project image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <strong>Autonomous Driving LLM-based Agent in Streaming Videos</strong>
              <br/>
              <a href="https://drive.google.com/file/d/10AK8VzfrYUEeh5E8xF6q3ioGEaS79OKL/view?usp=sharing" style="color:darkblue;">Report</a>
              <ul>
                <li>Utilized multimodal models such as InstructBLIP and Video-Llava for in-context learning on driving datasets</li>
                <li>Implemented text based memory systems for LLM agents in streaming environments</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="photos/adlr.png" alt="ADLR Project Image" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <strong>Diffusion Robot Path Planning</strong>
              <br/>
              <a href="poster1.html" style="color:darkblue;">Project Poster</a> 
              <ul>
                <li> Replication of "Planning with Diffusion for Flexible Behavior Synthesis" (Janner et al., 2022) in for 2D Maze environment in PyTorch </li>
                <li> Extension of the paper to 3D environment of robotic arm with 7 DoF </li>
                <li> Training on Google Cloud Engine </li>
              </ul>
            </td>
          </tr>
        </table>

        <!-- Experience Section -->
        <h2>Experience</h2>
        <table style="width:100%;border-spacing:0px;margin-right:auto;margin-left:auto;">
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:100px">
              <img src="photos/huawei.png" alt="Huawei Logo" style="width:auto; height:auto; max-width:85%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <strong>Huawei Munich Research Center</strong> <br/>
              Student Worker (November 2024 - April 2025)
              <ul>
                <li>Using video language models for autonomous driving tasks</li>
                <li>Experiments on fine-grained action understanding of videos in traffic scenarios </li>
                <li>Utilizing existing autonomous driving datasets to curate a more descriptive dataset to be used for retrieval</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="photos/fraunhofer.png" alt="Fraunhofer Logo" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <strong>Fraunhofer</strong> <br/>
              Student Worker (November 2023 - November 2024)
              <ul>
                <li>Simulation of centralized MPC control of multi-agent drone system for navigations, and experiments</li>
                <li>Developing learning-based alternatives to bypass linear solvers of CasADi for speedup </li>
              </ul>
            </td>
          </tr>
          <tr>
            <td style="padding:2.5%;width:25%;vertical-align:middle;min-width:120px">
              <img src="photos/uoe.png" alt="UoE Logo" style="width:auto; height:auto; max-width:100%;" />
            </td>
            <td style="padding:2.5%;width:75%;vertical-align:middle">
              <strong>The University of Edinburgh</strong> <br/>
              Student Researcher (June 2020 - April 2024, Online)
              <ul>
                <li>Q-Learning based models for behavioral analysis in the Morris Water Maze experiment </li>
                <li>Developed the cognitive value matric to assess the spatial navigation capabilities in the simulations </li>
                <li>Featured a poster at the 49th European Brain and Behaviour Society (EBBS) Meeting</li>
              </ul>
            </td>
          </tr>
        </table>

        <!-- Footer Section -->
        <table style="width:100%;border-spacing:0px;margin-right:auto;margin-left:auto;">
          <tr>
            <td>
              <br>
              <p style="text-align:center;font-size:small;">
                Design and source code from <a style="font-size:small;" href="https://jonbarron.info">Jon Barron's website</a>
              </p>
            </td>
          </tr>
        </table>
      </td>
    </tr>
  </table>
</body>
</html>
